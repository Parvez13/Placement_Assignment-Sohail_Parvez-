{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1sLfSCTtOuwp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMukPY2_P4X4",
        "outputId": "907d99b1-4287-47d5-f843-63577d0266b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "X_train = X_train.reshape((-1,28,28,1)).astype('float32')/255.0\n",
        "X_test = X_test.reshape((-1,28,28,1)).astype('float32')/255.0\n"
      ],
      "metadata": {
        "id": "1Ylt3ggCQKH8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define first CNN Architecture\n",
        "model_1 = Sequential([\n",
        "    layers.Conv2D(16, (3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "psJS8ESORXVb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model 2\n",
        "model_2 = Sequential([\n",
        "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    layers.Conv2D(32,(3,3),activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation='relu'),\n",
        "    layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bHRsxgIWSAeX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the third CNN architecture\n",
        "model_3 = Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "uNgqPn8FSgDQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the models\n",
        "import pandas as pd\n",
        "models = [model_1, model_2, model_3]\n",
        "model_names = ['Model 1', 'Model 2', 'Model 3']\n",
        "accuracies = []\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Training {model_names[i]}...\")\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=128, verbose=1)\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Create a comparison table\n",
        "comparison_table = pd.DataFrame({\n",
        "    'Model': model_names,\n",
        "    'Accuracy': accuracies\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHtUX6TCS1N1",
        "outputId": "65535195-cec7-438d-c3ba-f4564ead29e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1...\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 14s 5ms/step - loss: 0.2900 - accuracy: 0.9187\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0869 - accuracy: 0.9751\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0599 - accuracy: 0.9824\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0465 - accuracy: 0.9865\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0380 - accuracy: 0.9892\n",
            "Training Model 2...\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 6ms/step - loss: 0.1795 - accuracy: 0.9469\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0470 - accuracy: 0.9855\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0303 - accuracy: 0.9906\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0224 - accuracy: 0.9930\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0154 - accuracy: 0.9952\n",
            "Training Model 3...\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 4s 5ms/step - loss: 0.1841 - accuracy: 0.9446\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0480 - accuracy: 0.9851\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0313 - accuracy: 0.9897\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0214 - accuracy: 0.9935\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0165 - accuracy: 0.9945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(comparison_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZJG5ttdTm4a",
        "outputId": "39103fb6-f515-4aa8-821b-5762a3f0e5c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Model  Accuracy\n",
            "0  Model 1    0.9829\n",
            "1  Model 2    0.9884\n",
            "2  Model 3    0.9891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lVPnJ__4TnXE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}